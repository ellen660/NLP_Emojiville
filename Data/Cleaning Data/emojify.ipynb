{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from langdetect import detect, DetectorFactory\n",
    "from nltk.tokenize import TweetTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .txt file line by line into a DataFrame\n",
    "with open('Clean Dataset/emojify_rawdata', 'r', encoding='utf-8') as file:\n",
    "    data = file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squad arriving for Game 2 üöÄ\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dude is like 5‚Äô8 140 pounds his dick was long and strong(always the little dudes carrying the üçÜ) ü§™üôÉ\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOLLOWERSüëá\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I CANT BREATIUHW üíÄüíÄüíÄ\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Ô∏è‚É£4Ô∏è‚É£ hours 'til our schedule drops!\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   tweet\n",
       "0                                                                          Squad arriving for Game 2 üöÄ\\n\n",
       "1  Dude is like 5‚Äô8 140 pounds his dick was long and strong(always the little dudes carrying the üçÜ) ü§™üôÉ\\n\n",
       "2                                                                                           FOLLOWERSüëá\\n\n",
       "3                                                                                 I CANT BREATIUHW üíÄüíÄüíÄ\\n\n",
       "4                                                                2Ô∏è‚É£4Ô∏è‚É£ hours 'til our schedule drops!\\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame where each line is a row\n",
    "df2 = pd.DataFrame(data, columns=['tweet'])\n",
    "\n",
    "# Display the first few rows\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to drop duplicates \n",
    "\n",
    "# Compute a hash for each row\n",
    "df2['hash'] = pd.util.hash_pandas_object(df2, index=False)\n",
    "\n",
    "# Drop duplicates based on the hash column\n",
    "df2 = df2.drop_duplicates(subset=['hash'])\n",
    "\n",
    "# Drop the hash column after filtering\n",
    "df2 = df2.drop(columns=['hash'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18883592\n"
     ]
    }
   ],
   "source": [
    "#Check number of tweets\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping only tweets with 1 emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping only tweets with 1 emoji in them for simplicity\n",
    "\n",
    "def filter_tweets_with_one_emoji(df, tweets_column):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only rows where the specified column contains exactly one emoji.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - tweets_column (str): The name of the column containing the tweets.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A filtered DataFrame with rows containing exactly one emoji.\n",
    "    \"\"\"\n",
    "    # Function to count emojis in a string\n",
    "    def count_emojis(tweet):\n",
    "        return sum(1 for char in tweet if char in emoji.EMOJI_DATA)\n",
    "\n",
    "    # Filter rows with exactly one emoji\n",
    "    filtered_df = df[df[tweets_column].apply(count_emojis) == 1]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "df2 = filter_tweets_with_one_emoji(df2, tweets_column=\"tweet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5187482\n"
     ]
    }
   ],
   "source": [
    "#Check number of tweets\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making text lowercase, removing any URLs, Hashtags, or Mentions\n",
    "def clean_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower().strip()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df2['clean_tweet'] = df2['tweet'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Squad arriving for Game 2 üöÄ\\n</td>\n",
       "      <td>squad arriving for game 2 üöÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOLLOWERSüëá\\n</td>\n",
       "      <td>followersüëá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEW || Zach &amp;amp; Jack at Limelight tonight! (...</td>\n",
       "      <td>new || zach &amp;amp; jack at limelight tonight! (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I am SO scared of birdsü§ß\\n</td>\n",
       "      <td>i am so scared of birdsü§ß</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This is one of my favorite songs to sing in th...</td>\n",
       "      <td>this is one of my favorite songs to sing in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Took my goat to get groomed for the first time...</td>\n",
       "      <td>took my goat to get groomed for the first time üòÇ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  \\\n",
       "0                       Squad arriving for Game 2 üöÄ\\n   \n",
       "2                                        FOLLOWERSüëá\\n   \n",
       "5   NEW || Zach &amp; Jack at Limelight tonight! (...   \n",
       "7                          I am SO scared of birdsü§ß\\n   \n",
       "10  This is one of my favorite songs to sing in th...   \n",
       "11  Took my goat to get groomed for the first time...   \n",
       "\n",
       "                                          clean_tweet  \n",
       "0                         squad arriving for game 2 üöÄ  \n",
       "2                                          followersüëá  \n",
       "5   new || zach &amp; jack at limelight tonight! (...  \n",
       "7                            i am so scared of birdsü§ß  \n",
       "10  this is one of my favorite songs to sing in th...  \n",
       "11   took my goat to get groomed for the first time üòÇ  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the data\n",
    "tokenizer=TweetTokenizer()\n",
    "\n",
    "def tokenize_and_replace_emojis(text):\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "df2['tokens'] = df2['clean_tweet'].apply(tokenize_and_replace_emojis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[squad, arriving, for, game, 2, üöÄ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[followers, üëá]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[new, |, |, zach, &amp;, jack, at, limelight, tonight, !, (, april, 17, ), ¬©, Ô∏ènvmbesson]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[i, am, so, scared, of, birds, ü§ß]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[this, is, one, of, my, favorite, songs, to, sing, in, this, episode, ‚ù§, Ô∏è]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18883571</th>\n",
       "      <td>[this, dude, is, so, bay, area, üòÇ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18883572</th>\n",
       "      <td>[take, advantage, of, me, &amp;, i, ‚Äô, ll, ice, you, out, ü§´]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18883575</th>\n",
       "      <td>[i, stay, getting, ignored, üòî]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18883583</th>\n",
       "      <td>[i, want, some, crawfish, but, i, only, want, it, from, this, one, place, üò©]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18883586</th>\n",
       "      <td>[goodmorning, üòÄ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5187482 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         tokens\n",
       "0                                                            [squad, arriving, for, game, 2, üöÄ]\n",
       "2                                                                                [followers, üëá]\n",
       "5         [new, |, |, zach, &, jack, at, limelight, tonight, !, (, april, 17, ), ¬©, Ô∏ènvmbesson]\n",
       "7                                                             [i, am, so, scared, of, birds, ü§ß]\n",
       "10                  [this, is, one, of, my, favorite, songs, to, sing, in, this, episode, ‚ù§, Ô∏è]\n",
       "...                                                                                         ...\n",
       "18883571                                                     [this, dude, is, so, bay, area, üòÇ]\n",
       "18883572                               [take, advantage, of, me, &, i, ‚Äô, ll, ice, you, out, ü§´]\n",
       "18883575                                                         [i, stay, getting, ignored, üòî]\n",
       "18883583           [i, want, some, crawfish, but, i, only, want, it, from, this, one, place, üò©]\n",
       "18883586                                                                       [goodmorning, üòÄ]\n",
       "\n",
       "[5187482 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/joyse/Desktop/6.8610/Research/Emojiville/Data Processing/Clean Dataset\"\n",
    "filename1 = 'emojify_cleaned.csv'\n",
    "\n",
    "file_path1 = os.path.join(folder_path, filename1)\n",
    "\n",
    "df2.to_csv(file_path1, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a Smaller Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = df2.sample(n=10000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/joyse/Desktop/6.8610/Research/Emojiville/Data Processing/Clean Dataset\"\n",
    "filename1 = 'emojify_cleaned_10k.csv'\n",
    "\n",
    "file_path1 = os.path.join(folder_path, filename1)\n",
    "\n",
    "random_sample.to_csv(file_path1, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(random_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12733535</th>\n",
       "      <td>[if, not, later, ,, when, ?, üçë]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382379</th>\n",
       "      <td>[üîó, |, the, izombie, 4x08, page, is, now, up, !, containing, trivia, ,, quotes, ,, reviews, ,, a, look, at, liv's, style, ,, comic, slides, gifs, ,, the, b, ‚Ä¶]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17448398</th>\n",
       "      <td>[hearing, bts, at, work, still, amazes, me, üòç]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359951</th>\n",
       "      <td>[ayyy, this, is, lit, üî•]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11483372</th>\n",
       "      <td>[well, richard, i, jumped, in, the, shower, and, saved, her, so, back, off, üò°]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                   tokens\n",
       "12733535                                                                                                                                  [if, not, later, ,, when, ?, üçë]\n",
       "1382379   [üîó, |, the, izombie, 4x08, page, is, now, up, !, containing, trivia, ,, quotes, ,, reviews, ,, a, look, at, liv's, style, ,, comic, slides, gifs, ,, the, b, ‚Ä¶]\n",
       "17448398                                                                                                                   [hearing, bts, at, work, still, amazes, me, üòç]\n",
       "1359951                                                                                                                                          [ayyy, this, is, lit, üî•]\n",
       "11483372                                                                                   [well, richard, i, jumped, in, the, shower, and, saved, her, so, back, off, üò°]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample2=random_sample.sample(n=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/joyse/Desktop/6.8610/Research/Emojiville/Data Processing/Clean Dataset\"\n",
    "filename1 = 'emojify_cleaned_500.csv'\n",
    "\n",
    "file_path1 = os.path.join(folder_path, filename1)\n",
    "\n",
    "random_sample2.to_csv(file_path1, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
